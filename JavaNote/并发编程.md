## 上下文切换
### 时间片
 即使是单核CPU也能够运行多线程程序，多个线程会争取CPU的执行权，也叫时间片（通常十几），cpu会通过时间片分配算法在线程之间来回切换，对于用户来
说就像这些线程在并行执行一样。
### 并行一定比串行快吗？ 
 不一定，CPU由一个线程切换到另一个线程，需要保留当下的执行状态（执行到了哪一行，有哪些变量和变量值），在下次继续执行该线程时恢复到原来的状态，这个保存-恢复是会消耗额外空间的。   
### 如何避免频繁的上线文切换
#### 降低锁力度 
 对数据进行分段id哈希取模，每个线程操作其中一段数据，这在concurrentHashMap中有所体现。
#### CAS无锁操作
 synchronized锁释放-获得就会引起上下文切换，可以采用CAS操作实现来保证操作的原子性，但频繁的CAS也会消耗CPU
#### 使用最少线程
 线程的创建和销毁都会消耗系统资源，因此尽量使用池化技术管理线程，同事也避免了CPU在大量线程之间切换的问题
 
### 资源限制的挑战
 软件资源：池化复用 1.数据库连接数 2.socket连接数
 硬件资源：带宽有限

## 并发机制的底层原理实现
### 本地内存和线程安全问题
#### 缓存行
CPU不会直接与内存交互，而是通过总线将数据读到自己的一个缓存行中
#### 本地内存
虚拟出来的概念，实际上并不存在，其囊括了缓存行，写缓冲区等概念
#### 线程安全问题
究其原因就是线程在自己的本地内存中操作共享变量的，仅对执行自己的处理器可见而对其他处理器是不可见的，而他们在自己的本地内存对共享变量的更新何时会刷新到主内存、会按照什么顺序刷新到主内存是不可预见的。

### volatile
为了解决线程安全问题，就要保证共享内存的可见性，而被volatile修饰的变量在线程之间是可见的，volatile能够保证共享变量能被一致性的更新
#### 语义：
写volatile共享变量时会做两个事：     
 *锁定缓存行：在某个处理器将共享变量数据写入自己的写缓冲区（对应线程对本地内存中的共享变量做修改）时，会使用缓存锁定其他也读取了该共享变量的缓存行，使其他处理器不能访问该共享变量。
 *刷新内存：该处理器将自己写缓存区中的所有数据刷新到主内存，由缓存一致性来保证其他CPU重新读数据。
### synchronized 
每个对象都有一个monitorenter(监视器)与之对应
#### 同步
 * 同步代码块 在代码执行前获取对象的锁，对象的锁同时只能被一个线程持有，此时如果有其他线程尝试获取则会进入锁的阻塞队列，线程进入BLOCKED状态。
 * 同步方法 使用方法修饰符ACC_ASYNCHRONIZED，原理和监视器差不多
#### 锁
  主要采用了4种锁机制
  * 无锁  初始状况（没有任何线程访问过同步块）
  * 偏向锁    
    如果仅有几个线程，会出现同一个线程不断访问访问共享资源的情况，此时如果还使用获得-释放，那么效率会很低，于是引入了偏向锁，在一个线程访问同步块时会有如下操作： 1.判断对象头的Mark Word中的线程ID是否是当前线程，如果是，直接进入同步快 2.如果不是，查看Mark Word中“是否是偏向锁”这一标志位，如果是偏向锁并且出现了锁争用的情况，偏向锁升级为轻量锁 3.如果不是偏向锁，则表示无锁状态，CAS将Mark Word中的线程ID指向当前线程，进入同步块。
  * 轻量级锁        
    如果并发升级，偏向锁会升级为轻量级锁。   
  * 重量级锁    
    即排它锁
### 原子操作的原理   
  * synchronized关键字保证同步快在同一时刻只能有一个线程访问，同步块中的操作自然具备原子性。
  * CAS 锁获取-释放会引起上下文切换，对系统资源的消耗比较大。JAVA并发包中提供了很多原子操作类，原理就是CAS更新（也称乐观锁，认为并发没有那么高，总能更新成功）。CAS compare and swap，涉及两个术语，预期值，更新值。举个栗子：A,B两个线程同时对i=1进行++操作，首先A线程读到的值为1，执行i++操作并刷新到主内存时，比较一下主内存中的值是否是1（预期值），如果是就将共享变量替换为2（更新值），后来B也准备将i=2（更新值）刷新到主内存时，发现主内存中的值i不等于1（预期值），于是更新失败，重新读取i=2，进行CAS更新，这个不断尝试CAS的过程成为自旋。
 
